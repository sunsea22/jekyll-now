---
layout: post
title: 大数据面试题整理
---

bigdata面试


   面试机器学习、大数据岗位时遇到的各种问题

### 无监督和有监督算法的区别
监督学习：通过已有的训练样本（即已知数据以及其对应的输出）来训练，从而得到一个最优模型，再利用这个模型将所有新的数据样本映射为相应的输出结果，对输出结果进行简单的判断从而实现分类的目的，那么这个最优模型也就具有了对未知数据进行分类的能力。

无监督学习：我们事先没有任何训练数据样本，需要直接对数据进行建模。


### 逻辑斯蒂回归（LR）VS 决策树 VS 随机森林 VS SVM
LR与SVM

#### 不同
1. logistic regression适合需要得到一个分类概率的场景，SVM则则没有分类概率
2. LR其实同样可以使用kernel，但是LR没有support vector在计算复杂度上会高出很多。如果样本量很大并且需要的是一个复杂模型，那么建议SVM
3. 如果样本比较少，模型有比较复杂。那么建议SVM，它有一套比较好的解构风险最小化理论的保障，比如large margin和soft margin

#### 相同
1. 由于hinge loss和entropy loss很接近，因此得出来的两个分类面是非常接近的
2. 都是在两个loss上做了一个regularization

#### 逻辑回归
优点：
1.适合需要得到一个分类概率的场景

2.实现效率较高

3.对逻辑回归而言，多重共线性并不是问题，它可以结合L2正则化来解决；

4.逻辑回归广泛的应用于工业问题上
 
缺点：
1.当特征空间很大时，逻辑回归的性能不是很好；

2.不能很好地处理大量多类特征或变量；

4.对于非线性特征，需要进行转换；

5.依赖于全部的数据特征，当特征有缺失的时候表现效果不好

#### 决策树
与决策树相关的最大问题是它们属于高度偏见型模型。你可以在训练集上构建决策树模型，而且其在训练集上的结果可能优于其它算法，但你的测试集最终会证明它是一个差的预测器。你必须对树进行剪枝，同时结合交叉验证才能得到一个没有过拟合的决策树模型。

#### 随机森林
随机森林在很大程度上克服了过拟合这一缺陷，其本身并没有什么特别之处，但它却是决策树一个非常优秀的扩展。

优点：
1.直观的决策规则

2.可以处理非线性特征

3.考虑了变量之间的相互作用

缺点：
1.训练集上的效果高度优于测试集，即过拟合[随机森林克服了此缺点]

2.没有将排名分数作为直接结果

#### SVM
支持向量机的特点是它依靠边界样本来建立需要的分离曲线，它可以处理非线性决策边界。支持向量机能够处理大的特征空间，也因此成为文本分析中最受欢迎的算法之一，由于文本数据几乎总是产生大量的特征，所以在这种情况下逻辑回归并不是一个非常好的选择。

优点：
1.能够处理大型特征空间

2.能够处理非线性特征之间的相互作用

3.无需依赖整个数据

缺点：
1.当观测样本很多时，效率并不是很高

2.有时候很难找到一个合适的核函数



### Hadoop与Spark的特点及应用场景
Hadoop是离线计算，基于磁盘，每次运算之后的结果需要存储在HDFS里面，下次再用的话，还需要读出来进行一次计算，磁盘IO开销比较大。底层基于HDFS存储文件系统。并且Hadoop只有Map和Reduce两种接口，相对于Spark来说太少了。

Spark里面一个核心的概念就是RDD，弹性分布式数据集。Spark支持内存计算模型，用户可以指定存储策略，当内存不够的时候，可以放置到磁盘上。并且Spark提供了一组RDD的接口，Transformation和Action。Transformation是把一个RDD转换成为另一个RDD以便形成Lineage血统链，这样当数据发生错误的时候可以快速的依靠这种继承关系恢复数据。Action操作是启动一个job并开始真正的进行一些计算并把返回的结果可以给Driver或者是缓存在worker里面。


### 简单说一下hadoop和spark的shuffle过程
hadoop：map端保存分片数据，通过网络收集到reduce端
spark：spark的shuffle是在DAGSchedular划分Stage的时候产生的，TaskSchedule要分发Stage到各个worker的executor






----
****

